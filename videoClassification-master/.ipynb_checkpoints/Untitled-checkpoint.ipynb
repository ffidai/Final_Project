{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAGE\n",
    "# python train.py --dataset data --model model/activity.model --label-bin model/lb.pickle --epochs 80\n",
    "\n",
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "#matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # construct the argument parser and parse the arguments\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-d\", \"--dataset\", required=True,\n",
    "# \thelp=\"path to input dataset\")\n",
    "# ap.add_argument(\"-m\", \"--model\", required=True,\n",
    "# \thelp=\"path to output serialized model\")\n",
    "# ap.add_argument(\"-l\", \"--label-bin\", required=True,\n",
    "# \thelp=\"path to output label binarizer\")\n",
    "# ap.add_argument(\"-e\", \"--epochs\", type=int, default=25,\n",
    "# \thelp=\"# of epochs to train our network for\")\n",
    "# ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
    "# \thelp=\"path to output loss/accuracy plot\")\n",
    "# args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "imagePaths = ['data\\\\Cyclone\\\\0.jpg', 'data\\\\Cyclone\\\\1.jpg', 'data\\\\Cyclone\\\\2.jpg', 'data\\\\Cyclone\\\\3.jpg', 'data\\\\Cyclone\\\\4.jpg', 'data\\\\Cyclone\\\\5.jpg', 'data\\\\Earthquake\\\\0.jpg', 'data\\\\Earthquake\\\\1.jpg', 'data\\\\Earthquake\\\\2.jpg', 'data\\\\Earthquake\\\\3.jpg', 'data\\\\Earthquake\\\\4.jpg', 'data\\\\Earthquake\\\\5.jpg', 'data\\\\Flood\\\\0.jpg', 'data\\\\Flood\\\\1.jpg', 'data\\\\Flood\\\\2.jpg', 'data\\\\Flood\\\\3.jpg', 'data\\\\Flood\\\\4.jpg', 'data\\\\Flood\\\\5.jpg', 'data\\\\Wildfire\\\\0.jpg', 'data\\\\Wildfire\\\\1.jpg', 'data\\\\Wildfire\\\\2.jpg', 'data\\\\Wildfire\\\\3.jpg', 'data\\\\Wildfire\\\\4.jpg', 'data\\\\Wildfire\\\\5.jpg']\n",
      "Cyclone\n",
      "Cyclone\n",
      "Cyclone\n",
      "Cyclone\n",
      "Cyclone\n",
      "Cyclone\n",
      "Earthquake\n",
      "Earthquake\n",
      "Earthquake\n",
      "Earthquake\n",
      "Earthquake\n",
      "Earthquake\n",
      "Flood\n",
      "Flood\n",
      "Flood\n",
      "Flood\n",
      "Flood\n",
      "Flood\n",
      "Wildfire\n",
      "Wildfire\n",
      "Wildfire\n",
      "Wildfire\n",
      "Wildfire\n",
      "Wildfire\n",
      "labels =  ['Cyclone', 'Cyclone', 'Cyclone', 'Cyclone', 'Cyclone', 'Cyclone', 'Earthquake', 'Earthquake', 'Earthquake', 'Earthquake', 'Earthquake', 'Earthquake', 'Flood', 'Flood', 'Flood', 'Flood', 'Flood', 'Flood', 'Wildfire', 'Wildfire', 'Wildfire', 'Wildfire', 'Wildfire', 'Wildfire']\n",
      "data =  ['data', array([[[240, 241, 239]]], dtype=uint8), array([[[ 40,  88, 147]]], dtype=uint8), array([[[35, 44, 50]]], dtype=uint8), array([[[251, 247, 247]]], dtype=uint8), array([[[171, 175, 179]]], dtype=uint8), array([[[197, 198, 202]]], dtype=uint8), array([[[111, 114, 117]]], dtype=uint8), array([[[90, 89, 87]]], dtype=uint8), array([[[133, 134, 126]]], dtype=uint8), array([[[35, 34, 37]]], dtype=uint8), array([[[161, 146, 143]]], dtype=uint8), array([[[62, 73, 77]]], dtype=uint8), array([[[152, 156, 165]]], dtype=uint8), array([[[ 80,  81, 102]]], dtype=uint8), array([[[214, 190, 178]]], dtype=uint8), array([[[82, 81, 91]]], dtype=uint8), array([[[105,  95,  93]]], dtype=uint8), array([[[204, 192, 176]]], dtype=uint8), array([[[148,  39,  22]]], dtype=uint8), array([[[218,  91,  19]]], dtype=uint8), array([[[22,  3,  2]]], dtype=uint8), array([[[131,  35,  21]]], dtype=uint8), array([[[81, 45, 33]]], dtype=uint8), array([[[94, 82, 55]]], dtype=uint8)]\n"
     ]
    }
   ],
   "source": [
    "LABELS = set([\"Cyclone\", \"Earthquake\", \"Flood\", \"Wildfire\"])\n",
    "\n",
    "# grab the list of images in our dataset directory, then initialize\n",
    "# the list of data (i.e., images) and class images\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(\"data\"))\n",
    "data = ['data']\n",
    "labels = []\n",
    "print(\"imagePaths =\" , imagePaths)\n",
    "\n",
    "# loop over the image paths\n",
    "for imagePath in imagePaths:\n",
    "    # extract the class label from the filename\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    print(label)\n",
    "    \n",
    "#     # if the label of the current image is not part of of the labels\n",
    "#     # are interested in, then ignore the image\n",
    "    if label not in LABELS:\n",
    "        continue\n",
    "\n",
    "#     # load the image, convert it to RGB channel ordering, and resize\n",
    "#     # it to be a fixed 224x224 pixels, ignoring aspect ratio\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    #image = cv2.resize(image, (1, 1))\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "\n",
    "#     # update the data and labels lists, respectively\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "\n",
    "print(\"labels = \", labels)\n",
    "print(\"data = \", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data =  (25,)\n",
      "labels =  (24, 4)\n"
     ]
    }
   ],
   "source": [
    "# convert the data and labels to NumPy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "#lb = LabelEncoder()\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "\n",
    "\n",
    "\n",
    "print(\"data = \", data.shape)\n",
    "print(\"labels = \", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [25, 24]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-6a1ec6a5d781>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# partition the data into training and testing splits using 80% of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# the data for training and the remaining 20% for testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2029\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2031\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2033\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 204\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [25, 24]"
     ]
    }
   ],
   "source": [
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.50, stratify=labels, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
